{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aaron-abrams-uva/DS1002-S24/blob/main/Pandas/Data_manipulation_student.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74Uu462c0jcB"
      },
      "source": [
        "## Data wrangling with pandas\n",
        "DS 1002: Programming for Data Science\n",
        "\n",
        "\n",
        "\n",
        "### PREREQUISITES\n",
        "- variables\n",
        "- data types\n",
        "- operators\n",
        "- list comprehensions (not essential)\n",
        "- numpy arrays (not essential)\n",
        "- earlier pandas notebooks\n",
        "\n",
        "\n",
        "### SOURCES\n",
        "- ten minutes to pandas  \n",
        "https://pandas.pydata.org/pandas-docs/stable/user_guide/10min.html\n",
        "\n",
        "\n",
        "- lambda (anonymous) functions  \n",
        "https://realpython.com/python-lambda/#anonymous-functions\n",
        "\n",
        "\n",
        "- pivot_table()  \n",
        "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.pivot_table.html\n",
        "\n",
        "\n",
        "- concat()  \n",
        "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.concat.html\n",
        "\n",
        "\n",
        "- merge()  \n",
        "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.merge.html\n",
        "\n",
        "\n",
        "- get_dummies()  \n",
        "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html\n",
        "\n",
        "\n",
        "\n",
        "### OBJECTIVES\n",
        "- Introduce more advanced pandas dataframe operations for data munging\n",
        "\n",
        "\n",
        "\n",
        "### CONCEPTS\n",
        "\n",
        "- DataFrame\n",
        "- `apply()`\n",
        "- aggregation using split-apply-combine\n",
        "- `pivot_table()`\n",
        "- `groupby()`\n",
        "- `concat()`\n",
        "- merging/joining dataframes with `merge()`, `concat()`\n",
        "- reshaping data\n",
        "- dummy coding categorical data\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "## Additional Pandas DataFrame Functionality\n",
        "\n",
        "In earlier pandas notebooks we covered *data frames* (creating, modifying, subsetting, etc) and *cleaning*.  \n",
        "These notes will demonstrate further methods for data munging and analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-NoFRXZX0jcD"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L-VivBL4GLCM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZElo_qI0jcD"
      },
      "source": [
        "#### Load Iris"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wlxdQd7X0jcD"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "iris = sns.load_dataset('iris')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PE03LQ180jcE"
      },
      "outputs": [],
      "source": [
        "iris.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tcGu62qe0jcE"
      },
      "outputs": [],
      "source": [
        "# return the size of the object in bytes\n",
        "import sys\n",
        "sys.getsizeof(iris)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JtxkJHAN0jcE"
      },
      "source": [
        "## Apply Lambda Functions with `.apply()`\n",
        "\n",
        "Apply a transformation to each record. Uses a `lambda` function."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(lambda x: x**2) (3)\n",
        "\n",
        "# high_ord_func = lambda x, func: x + func(x)\n",
        "# high_ord_func(23, lambda x: x * x)\n"
      ],
      "metadata": {
        "id": "nbneLlg2Eayo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HROP05S8Eaql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ls9c907a0jcE"
      },
      "outputs": [],
      "source": [
        "iris['sepal_len_sq'] = iris.sepal_length.apply(lambda x: x**2)\n",
        "iris.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_FoIw9N0jcE"
      },
      "source": [
        "Transformation involving multiple columns. Uses `axis=1` to access columns.  \n",
        "Compute average of `sepal_length`, `sepal_width`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WppXA-mf0jcE"
      },
      "outputs": [],
      "source": [
        "iris['sepal_len_wid_avg'] = iris[['sepal_length','sepal_width']].apply(lambda x: (x.sepal_length+x.sepal_width)/2, axis=1)\n",
        "iris.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYMeTmN50jcF"
      },
      "source": [
        "### TRY FOR YOURSELF (UNGRADED EXERCISES)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2I6a7J10jcF"
      },
      "source": [
        "1) Use `apply()` to append a new column that is the minimum of (petal_length, petal_width)\n",
        "\n",
        "Print the head, tail of the new dataframe to check things look correct."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dpi1yL6i0jcF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJrioYQD0jcF"
      },
      "source": [
        "## Aggregation\n",
        "\n",
        "Involves one or more of:\n",
        "\n",
        "- splitting the data into groups\n",
        "- applying a function to each group\n",
        "- combining results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNpLFQiL0jcF"
      },
      "source": [
        "### `.groupby()`\n",
        "\n",
        "Compute mean of each column, grouped (separately) by species"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KCVBqLDY0jcF"
      },
      "outputs": [],
      "source": [
        "iris.groupby(\"species\").mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3wobqrv0jcF"
      },
      "source": [
        "### `pd.pivot_table()`\n",
        "\n",
        "Apply a function `aggfunc` to selected values grouped by columns\n",
        "\n",
        "[Details](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.pivot_table.html)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame({\"A\": [\"foo\", \"foo\", \"foo\", \"foo\", \"foo\",\n",
        "                         \"bar\", \"bar\", \"bar\", \"bar\"],\n",
        "                   \"B\": [\"one\", \"one\", \"one\", \"two\", \"two\",\n",
        "                         \"one\", \"one\", \"two\", \"two\"],\n",
        "                   \"C\": [\"small\", \"large\", \"large\", \"small\",\n",
        "                         \"small\", \"large\", \"small\", \"small\",\n",
        "                         \"large\"],\n",
        "                   \"D\": [1, 2, 2, 3, 3, 4, 5, 6, 7],\n",
        "                   \"E\": [2, 4, 5, 5, 6, 6, 8, 9, 9]})\n",
        "\n",
        "print(df)\n",
        "table = pd.pivot_table(df, values='D', index=['A', 'B'],\n",
        "                       columns=['C'], aggfunc=\"sum\")\n",
        "table"
      ],
      "metadata": {
        "id": "hjysSHpGHoBp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mw6g_OFT0jcF"
      },
      "source": [
        "Compute mean sepal length for each species:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "viDTVoLY0jcF"
      },
      "outputs": [],
      "source": [
        "pd.pivot_table(iris, values=\"sepal_length\", columns=[\"species\"], aggfunc = np.mean)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHGSEGdq0jcF"
      },
      "source": [
        "### TRY FOR YOURSELF (UNGRADED EXERCISES)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwPxKZVb0jcF"
      },
      "source": [
        "2) Use a pivot table to compute the following statistics on sepal_width and petal_width grouped by species:\n",
        "\n",
        "- median  \n",
        "- mean\n",
        "\n",
        "These can be computed together in a single call to `pivot_table()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LhkMuX1U0jcF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZ6TEYLQ0jcF"
      },
      "source": [
        "## Stacking and Unstacking\n",
        "\n",
        "Similar to pivoting, but requires -- and takes advantage of -- indexes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kOJpot620jcF"
      },
      "outputs": [],
      "source": [
        "iris_w_idx = iris.copy()\n",
        "\n",
        "# Give the original index a name\n",
        "iris_w_idx.index.name = 'obs_id'\n",
        "\n",
        "# Create a multi-index, using `species` as part of the key.\n",
        "iris_w_idx = iris_w_idx.reset_index().set_index(['species','obs_id'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HmhqcrZZ0jcF"
      },
      "outputs": [],
      "source": [
        "iris_w_idx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U19crOU90jcF"
      },
      "source": [
        "## `.unstack()`\n",
        "\n",
        "[Details](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.unstack.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TxiGYYGb0jcG"
      },
      "outputs": [],
      "source": [
        "iris_wide = iris_w_idx.sepal_length.unstack(fill_value=0).T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iXcF7V2P0jcG"
      },
      "outputs": [],
      "source": [
        "iris_wide"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6Igfktt0jcG"
      },
      "source": [
        "## `.stack()`\n",
        "\n",
        "[Details](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.stack.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mYWzAL0l0jcG"
      },
      "outputs": [],
      "source": [
        "iris_wide.T.stack().to_frame('sepal_length')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgkfrliw0jcG"
      },
      "source": [
        "## Combining DataFrames\n",
        "\n",
        "\n",
        "### `pd.concat()`  \n",
        "\n",
        "Concatenate pandas objects along an axis\n",
        "\n",
        "[Details](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.concat.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQL4CNOo0jcG"
      },
      "source": [
        "Create two dfs and vertically stack them"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L_-SU5vi0jcG"
      },
      "outputs": [],
      "source": [
        "df1 = pd.DataFrame(np.random.randn(3, 4))\n",
        "df2 = pd.DataFrame(np.random.randn(3, 4))\n",
        "\n",
        "print(df1)\n",
        "print('-'*45)\n",
        "print(df2)\n",
        "\n",
        "df3 = pd.concat([df1, df2], axis=0)\n",
        "\n",
        "print('-'*45)\n",
        "print(df3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RhT4mZX10jcG"
      },
      "source": [
        "**Concat columns**  \n",
        "This assumes that the indexes represent IDs of specific things or events"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oNnhN5Um0jcG"
      },
      "outputs": [],
      "source": [
        "df4 = pd.concat([df1,df2], axis = 1, keys = ['foo', 'bar'])\n",
        "\n",
        "df4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mNg16yx00jcG"
      },
      "outputs": [],
      "source": [
        "df4.foo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-z7nKOr_0jcG"
      },
      "outputs": [],
      "source": [
        "df4.bar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKa8b4b-0jcJ"
      },
      "source": [
        "### `merge()`\n",
        "\n",
        "SQL-style joining of tables (DataFrames)\n",
        "\n",
        "Important parameters include:\n",
        "\n",
        "- `how` : type of merge {'left', 'right', 'outer', 'inner', 'cross'}, default ‘inner’\n",
        "- `on`  : names to join on\n",
        "        \n",
        "[Details](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.merge.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCK6nxnc0jcJ"
      },
      "source": [
        "Create two tables, `left` and `right`. Then right join them on `key`.  \n",
        "Right join means include all records from table on right.  \n",
        "The `key` is used for matching up the records."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "id": "3AymIOuJ0jcJ"
      },
      "outputs": [],
      "source": [
        "left = pd.DataFrame({\"key\": [\"jamie\", \"bill\"], \"lval\": [15, 22]})\n",
        "right = pd.DataFrame({\"key\": [\"jamie\", \"bill\", \"asher\"], \"rval\": [4, 5, 8]})\n",
        "\n",
        "joined = pd.merge(left, right, on=\"key\", how=\"right\")\n",
        "\n",
        "print('---left')\n",
        "print(left)\n",
        "print('\\n---right')\n",
        "print(right)\n",
        "print('\\n---joined')\n",
        "print(joined)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BCzpDGhh0jcJ"
      },
      "source": [
        "Notice the NaN inserted into the record with key=asher, since the left table didn't contain the key."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7XeAzDy0jcJ"
      },
      "source": [
        "**Matching column names**  \n",
        "In this next example, the value columns have the same name: *val*.  Notice what happens to the column names."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k493cQfE0jcJ"
      },
      "outputs": [],
      "source": [
        "left = pd.DataFrame({\"key\": [\"jamie\", \"bill\"], \"val\": [15, 22]})\n",
        "right = pd.DataFrame({\"key\": [\"jamie\", \"bill\", \"asher\"], \"val\": [4, 5, 8]})\n",
        "\n",
        "joined = pd.merge(left, right, on=\"key\", how=\"right\")\n",
        "\n",
        "print('---left')\n",
        "print(left)\n",
        "print('\\n---right')\n",
        "print(right)\n",
        "print('\\n---joined')\n",
        "print(joined)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1U9vgGlb0jcJ"
      },
      "source": [
        "## `.join()`\n",
        "\n",
        "An SQL-like joiner, but this one takes advantage of indexes.\n",
        "\n",
        "Give our dataframes indexes and distinctive columns names.\n",
        "\n",
        "[Details](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.join.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bXCNyOio0jcJ"
      },
      "outputs": [],
      "source": [
        "left2 = left.set_index('key').rename(columns={'val':'val_1'})\n",
        "right2 = right.set_index('key').rename(columns={'val':'val_2'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WaYzO6hO0jcK"
      },
      "outputs": [],
      "source": [
        "left2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LQ5sQBcN0jcK"
      },
      "outputs": [],
      "source": [
        "right2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3188rMSg0jcK"
      },
      "outputs": [],
      "source": [
        "right2.join(left2) # defaults to first df (right2 in this case)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jNMtlvNl0jcK"
      },
      "outputs": [],
      "source": [
        "right2.join(left2, how = 'inner')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mT9eqPsG0jcK"
      },
      "source": [
        "## Summary\n",
        "\n",
        "* Use **join** if you have shared indexes\n",
        "* Use **merge** if you do not have shared indexes\n",
        "* Use **concat** to combine based on shared indexes or columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9NNgEbC0jcK"
      },
      "source": [
        "### TRY FOR YOURSELF (UNGRADED EXERCISES)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "224a36Gn0jcL"
      },
      "source": [
        "3) Redo the join exercise above, using an inner join instead of a right join.  \n",
        "Make sure the results make sense."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ESm7msSc0jcL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKsPqOVR0jcL"
      },
      "source": [
        "## `.reshape()`\n",
        "\n",
        "Changes the object's shape\n",
        "\n",
        "We illustrate creating pandas Series, extracting array of length 6, and reshaping to 3x2 array."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H0ycSUfD0jcL"
      },
      "outputs": [],
      "source": [
        "# create a series\n",
        "ser = pd.Series([1, 1, 2, 3, 5, 8])\n",
        "\n",
        "# extract values\n",
        "vals = ser.values\n",
        "\n",
        "print('orig data:', vals)\n",
        "print('orig type:', type(vals))\n",
        "print('orig shape:', vals.shape)\n",
        "\n",
        "# reshaping series\n",
        "reshaped_vals = vals.reshape((3, 2))\n",
        "\n",
        "print('\\n reshaped vals:')\n",
        "print(reshaped_vals)\n",
        "print('\\n new type:', type(reshaped_vals))\n",
        "print('new shape:', reshaped_vals.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6fj7RVp0jcL"
      },
      "source": [
        "Including -1 as one of the dimensions tells numpy: infer this dimension from the data and the other dimensions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PoFcq2jE0jcL"
      },
      "source": [
        "Example: enforce 3 columns:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "obB9jMRK0jcL"
      },
      "outputs": [],
      "source": [
        "vals.reshape(-1,3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3Pa6BB50jcL"
      },
      "source": [
        "Enforce 3 rows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AqvKKICq0jcL"
      },
      "outputs": [],
      "source": [
        "vals.reshape(3,-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6vF27oe0jcL"
      },
      "source": [
        "**IMPORTANT NOTE**  \n",
        "\n",
        "Notice the shape of original array: `(6,)`  \n",
        "This is a vector with one dimension, and is different from two-dimensional `(6,1)` array"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m929SPG00jcL"
      },
      "source": [
        "### TRY FOR YOURSELF (UNGRADED EXERCISES)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1ZG9J3a0jcL"
      },
      "source": [
        "4) Recreate the series from above with data [1, 1, 2, 3, 5, 8]  \n",
        "Extract the data from the series and reshape to 2x3.  \n",
        "Print both the reshaped data, and the dimensions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qihiKy4Q0jcL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uCgVX5g50jcL"
      },
      "source": [
        "## Categoricals\n",
        "\n",
        "Categorical data takes discrete values where computation on the values does not make sense.  \n",
        "Zip code is a typical example.\n",
        "\n",
        "To include categoricals in models, they must be converted to numeric.  \n",
        "\n",
        "### `get_dummies()`\n",
        "Dummy code categorical data\n",
        "\n",
        "The parameter `prefix` appends the prefix to column names (a good idea for later use)\n",
        "<!-- - `drop_first`: remove first level, as only `k-1` variables needed to represent `k` levels\n",
        "-->\n",
        "\n",
        "[Details](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y1PY0WXI0jcL"
      },
      "outputs": [],
      "source": [
        "cats = pd.DataFrame({'breed':['persian','persian','siamese','himalayan','burmese']})\n",
        "\n",
        "print('--categorical data')\n",
        "print(cats)\n",
        "\n",
        "cats = pd.get_dummies(cats.breed, prefix='breed')\n",
        "\n",
        "print('\\n')\n",
        "print('--dummified categorical data')\n",
        "print(cats)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-tx6pGk0jcL"
      },
      "source": [
        "Notice `burmese` was dropped (first level by alphabet)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHgIxq7Q0jcL"
      },
      "source": [
        "### TRY FOR YOURSELF (UNGRADED EXERCISES)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bbeHTO10jcM"
      },
      "source": [
        "5) The dataframe below contains two categoricals. Dummify each of them, giving them a prefix and dropping the first level from each.\n",
        "\n",
        "Print the new dataframe to insure correctness.\n",
        "\n",
        "Hint: You might want to dummify each column into separate new dataframes, and then merge them together by using:\n",
        "\n",
        "`pd.concat([df1, df2], axis=1)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9e9FAogW0jcM"
      },
      "outputs": [],
      "source": [
        "cats2 = pd.DataFrame({'breed':['persian','persian','siamese','himalayan','burmese'],\n",
        "                      'color':['calico','white','seal point','cream','sable']})"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4grETtxBNg-o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8SI-_uHr0jcM"
      },
      "source": [
        "---"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3.8.9 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.9"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}